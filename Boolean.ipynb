{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fe5514-c5a6-4b73-a332-964524295984",
   "metadata": {},
   "source": [
    "# Modelo Booleanno de Recuperación de la Información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f2ac4-b479-427c-bf3f-5eab0952f7d5",
   "metadata": {},
   "source": [
    "## Leer m documentos (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7c0f674a-6333-4a05-80bf-2a5b715e33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz # open pdf\n",
    "import re #regex\n",
    "import unicodedata # use unicode\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove accents\n",
    "    ## decompose unicode glyphs\n",
    "    normalized_string = unicodedata.normalize('NFKD',  text)\n",
    "    ## if a glyhp is compose, use its base form\n",
    "    no_accent_string = ''.join([c for c in normalized_string if not unicodedata.combining(c)])\n",
    "    # remove punctuation marks\n",
    "    no_punctuation_string = re.sub(r'[^\\w]+', ' ', no_accent_string)\n",
    "    return no_punctuation_string.strip()\n",
    "\n",
    "def dictionary(document):\n",
    "    # strip text of document to only get the main content\n",
    "    splited_words = re.split(r'[^\\w]+|\\s+', document)\n",
    "    terms = []\n",
    "    for w in splited_words:\n",
    "        if w not in terms:\n",
    "            terms.append(w)\n",
    "    return terms\n",
    "\n",
    "def read_raw_doc(doc_name):\n",
    "    doc = fitz.open(doc_name)\n",
    "    text = []\n",
    "    for page in doc:\n",
    "        text.append(page.get_text())\n",
    "    return ''.join(text)\n",
    "\n",
    "def clean_doc(doc_name):\n",
    "    clean_text(read_raw_doc(doc_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3445b1d0-de2e-468e-baaf-67d5c3478d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "73c8f967-e923-45bd-b27d-896dd8b102ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'a� en� el� pecho� en� su� esfuerzo� por� burlar� el\\nmolestísimo�viento,�se�deslizó�rápidamente�por�e'\n"
     ]
    }
   ],
   "source": [
    "raw_doc = read_raw_doc(\"documentos/1984.pdf\")\n",
    "unicode = raw_doc[182:182 + 100]\n",
    "print(repr(unicode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d0f90014-2001-40ed-b128-7bbc410e5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in unicode:\n",
    "#    print(f\"{c}:{repr(c)}:{ord(c)}\")\n",
    "    pass\n",
    "\n",
    "def line():\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f3f7deb9-1ec0-4582-ae4c-a2d82e85b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a� en� el� pecho� en� su� esfuerzo� por� burlar� el\n",
      "molestísimo�viento,�se�deslizó�rápidamente�por�e\n",
      "--------------------------------------------------------------------------------\n",
      "a� en� el� pecho� en� su� esfuerzo� por� burlar� el\n",
      "molestisimo�viento,�se�deslizo�rapidamente�por�e\n",
      "--------------------------------------------------------------------------------\n",
      "a en el pecho en su esfuerzo por burlar el molestisimo viento se deslizo rapidamente por e\n",
      "['a', 'en', 'el', 'pecho', 'en', 'su', 'esfuerzo', 'por', 'burlar', 'el', 'molestisimo', 'viento', 'se', 'deslizo', 'rapidamente', 'por', 'e']\n",
      "--------------------------------------------------------------------------------\n",
      "a  en  el  pecho  en  su  esfuerzo  por  burlar  el molestisimo viento, se deslizo rapidamente por e\n",
      "['a', 'en', 'el', 'pecho', 'en', 'su', 'esfuerzo', 'por', 'burlar', 'el', 'molestisimo', 'viento', 'se', 'deslizo', 'rapidamente', 'por', 'e']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## decompose unicode glyphs\n",
    "text = unicode\n",
    "normalized_string = unicodedata.normalize('NFKD',  text)\n",
    "print(normalized_string)\n",
    "line()\n",
    "## if a glyhp is compose, use its base form\n",
    "no_accent_string = ''.join([c for c in normalized_string if not unicodedata.combining(c)])\n",
    "print(no_accent_string)\n",
    "line()\n",
    "# remove punctuation marks\n",
    "def p(text, reg):\n",
    "    no_punctuation_string = re.sub(reg, ' ', text)\n",
    "    print(no_punctuation_string)\n",
    "    print(re.split(r'[^\\w]+', no_punctuation_string))\n",
    "    line()\n",
    "\n",
    "p(no_accent_string, r'[^\\w]+')\n",
    "p(no_accent_string, r\"[\\x00-\\x1F\\x7F\\uFFFD]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3e097611-cb72-4516-a847-f3f5f85e3dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a� en� el� pecho� en� su� esfuerzo� por� burlar� el\n",
      "molestísimo�viento,�se�deslizó�rápidamente�por�e\n",
      "--------------------------------------------------------------------------------\n",
      "a� en� el� pecho� en� su� esfuerzo� por� burlar� el\n",
      "molestisimo�viento,�se�deslizo�rapidamente�por�e\n",
      "--------------------------------------------------------------------------------\n",
      "a en el pecho en su esfuerzo por burlar el\n",
      "molestisimovientosedeslizorapidamentepore\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## decompose unicode glyphs\n",
    "text = unicode\n",
    "normalized_string = unicodedata.normalize('NFKD',  text)\n",
    "print(normalized_string)\n",
    "line()\n",
    "## if a glyhp is compose, use its base form\n",
    "no_accent_string = ''.join([c for c in normalized_string if not unicodedata.combining(c)])\n",
    "print(no_accent_string)\n",
    "line()\n",
    "# remove punctuation marks\n",
    "no_punctuation_string = re.sub(r'[^\\w\\s]', '', no_accent_string)\n",
    "print(no_punctuation_string)\n",
    "line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca428522-f613-4bfe-a1b8-baca75502dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'Hola', 'Hola', '']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary(\"\\n\\n\\nHola\\n\\n\\nHola\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21762593-e33e-45a4-8869-7dd394a89571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Como estas nino '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\" ¿Cómo estás niño? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ffe10f-a1ca-4240-bc92-ae87f72ded2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee4d9e-d6dc-4e12-8489-365967fa5a2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generar diccionario de términos de todo el corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b39f60e-4292-4d1b-a688-182cce2ed6c2",
   "metadata": {},
   "source": [
    "## Aplicar eliminación de palabras vacías (stopword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d1448-e9de-4b1e-957e-755bdd9e88a3",
   "metadata": {},
   "source": [
    "## Aplicar una técnica de stemming para reducir el \"Tamaño\" de las palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661151c1-a64b-4c73-b1c7-7663e6b8bec0",
   "metadata": {},
   "source": [
    "## Obtener una matriz binaria de la presencia de los términos en cada documento de todo el corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efeecca-857e-4dde-b2ce-cd29a16de7b7",
   "metadata": {},
   "source": [
    "## Diseñar una tabla hash que permita obtener mediante su función. llave -> valor <=> stem -> documentos donde aparece stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f95ab6-c1a4-4451-9095-179b0e67c6b8",
   "metadata": {},
   "source": [
    "## Leer la consulta booleana Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb2be11-54ee-450d-811c-a3caeee87732",
   "metadata": {},
   "source": [
    "### Aplicar stopword y stemming a la consulta Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46fa58-e5dd-4e1a-8841-3db099235036",
   "metadata": {},
   "source": [
    "### Aplicar la notación postfijo para el procesamiento de recuperación de la consulta dada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28350fd3-e513-435b-80dd-fb4fbaf6923e",
   "metadata": {},
   "source": [
    "## Presentar los nombre de los documentos obtenidos por Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d94e0-457a-4d3b-b541-9cd9dbac6e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
