{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fe5514-c5a6-4b73-a332-964524295984",
   "metadata": {},
   "source": [
    "# Modelo Booleanno de Recuperación de la Información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f2ac4-b479-427c-bf3f-5eab0952f7d5",
   "metadata": {},
   "source": [
    "## Leer m documentos (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c0f674a-6333-4a05-80bf-2a5b715e33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz # open pdf\n",
    "import re #regex\n",
    "import unicodedata # use unicode\n",
    "\n",
    "class Document:\n",
    "    def _content(self):\n",
    "        raw_doc = self._read_raw_doc(self.doc_name)\n",
    "        content = self._clean_doc(raw_doc)\n",
    "        self.content = content\n",
    "\n",
    "    def _freq(self):\n",
    "        self.freq_table = self.freq_term_table(self.terms(self.content))\n",
    "        self.terms = self.terms_unique(self.content)\n",
    "\n",
    "    def __init__(self, path_to_doc):\n",
    "        self.doc_name = path_to_doc\n",
    "        self._content()\n",
    "        self._freq()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.doc_name}\"\n",
    "        \n",
    "    def terms(self, clean_document):\n",
    "        return re.split(r'[^\\w]+', clean_document)\n",
    "\n",
    "    def terms_unique(self, clean_document):\n",
    "        splited_words = self.terms(clean_document)\n",
    "        terms = []\n",
    "        for w in splited_words:\n",
    "            if w not in terms:\n",
    "                terms.append(w)\n",
    "        return terms\n",
    "\n",
    "    def freq_term_table(self, terms):\n",
    "        freq_table = {}\n",
    "        for term in terms:\n",
    "            if term in freq_table:\n",
    "                freq_table[term] += 1\n",
    "            else:\n",
    "                freq_table[term] = 1\n",
    "        return freq_table\n",
    "\n",
    "    def _read_raw_doc(self, doc_name):\n",
    "        doc = fitz.open(doc_name)\n",
    "        text = []\n",
    "        for page in doc:\n",
    "            text.append(page.get_text())\n",
    "        return ''.join(text)\n",
    "\n",
    "    def _clean_doc(self, raw_doc):\n",
    "        # remove accents\n",
    "        ## decompose unicode glyphs\n",
    "        normalized_string = unicodedata.normalize('NFKD',  raw_doc)\n",
    "        ## if a glyhp is compose, use its base form\n",
    "        no_accent_string = ''.join([c for c in normalized_string if not unicodedata.combining(c)])\n",
    "        # remove punctuation marks\n",
    "        no_punctuation_string = re.sub(r'[^\\w]+', ' ', no_accent_string)\n",
    "        # strip text of document to only get the main content\n",
    "        return no_punctuation_string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2835d72-cdaf-48d7-b2f4-648aa8fd37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document(\"documentos/1984.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46145f8d-9980-4509-b105-2c46bff1300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984 GEORGE ORWELL PARTE PRIMERA CAPITULO I Era un dia luminoso y frio de abril y los relojes daban \n",
      "documentos/1984.pdf\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(doc\u001b[38;5;241m.\u001b[39mcontent[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(doc\u001b[38;5;241m.\u001b[39mdoc_name)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreq_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "print(doc.content[:100])\n",
    "print(doc.doc_name)\n",
    "print(doc.terms)\n",
    "print(doc.freq_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee4d9e-d6dc-4e12-8489-365967fa5a2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generar diccionario de términos de todo el corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b39f60e-4292-4d1b-a688-182cce2ed6c2",
   "metadata": {},
   "source": [
    "## Aplicar eliminación de palabras vacías (stopword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d1448-e9de-4b1e-957e-755bdd9e88a3",
   "metadata": {},
   "source": [
    "## Aplicar una técnica de stemming para reducir el \"Tamaño\" de las palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661151c1-a64b-4c73-b1c7-7663e6b8bec0",
   "metadata": {},
   "source": [
    "## Obtener una matriz binaria de la presencia de los términos en cada documento de todo el corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efeecca-857e-4dde-b2ce-cd29a16de7b7",
   "metadata": {},
   "source": [
    "## Diseñar una tabla hash que permita obtener mediante su función. llave -> valor <=> stem -> documentos donde aparece stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f95ab6-c1a4-4451-9095-179b0e67c6b8",
   "metadata": {},
   "source": [
    "## Leer la consulta booleana Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb2be11-54ee-450d-811c-a3caeee87732",
   "metadata": {},
   "source": [
    "### Aplicar stopword y stemming a la consulta Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46fa58-e5dd-4e1a-8841-3db099235036",
   "metadata": {},
   "source": [
    "### Aplicar la notación postfijo para el procesamiento de recuperación de la consulta dada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28350fd3-e513-435b-80dd-fb4fbaf6923e",
   "metadata": {},
   "source": [
    "## Presentar los nombre de los documentos obtenidos por Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d94e0-457a-4d3b-b541-9cd9dbac6e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
